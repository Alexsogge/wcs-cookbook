{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from  av.io import read\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "\"\"\"\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow import keras\n",
    "\n",
    "import string\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from  av.io import read\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import lite\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config, changes here have to be applied to Android-App too\n",
    "\n",
    "use_rotation_sensor = False\n",
    "use_accelerometer_sensor = True\n",
    "use_gyroscope_sensor = True\n",
    "use_magnetic_sensor = False\n",
    "sensor_inputs = 0\n",
    "normalize_vector = np.array([])\n",
    "\n",
    "if use_rotation_sensor:\n",
    "    sensor_inputs += 5\n",
    "    normalize_vector = np.append(normalize_vector, [1,1,1,1,1], axis=0)\n",
    "\n",
    "if use_accelerometer_sensor:\n",
    "    sensor_inputs += 3\n",
    "    normalize_vector = np.append(normalize_vector, [15,15,15], axis=0)\n",
    "    \n",
    "if use_gyroscope_sensor:\n",
    "    sensor_inputs += 3\n",
    "    normalize_vector = np.append(normalize_vector, [3,3,3], axis=0)\n",
    "\n",
    "if use_magnetic_sensor:\n",
    "    sensor_inputs += 3\n",
    "    normalize_vector = np.append(normalize_vector, [40,40,40], axis=0)\n",
    "\n",
    "\n",
    "cut_shape = (100, sensor_inputs)\n",
    "gestures = {0: 'noise', 1: 'Left', 2: 'Right'}\n",
    "gestures_reverse = {\"left\" : 1, \"noise\" : 0, \"right\" : 2}\n",
    "\n",
    "data_folder = \"data/\"\n",
    "patterns = {\"left\" : \"swipe_left_20*.mkv\", \"right\" : \"swipe_right_20*.mkv\", \"noise\" : \"*noise*.mkv\"} \n",
    "data_split_folder = \"data_singled/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Data-Handling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, lable=None):\n",
    "    data, meta = read(\" \".join([\"a:\" + str(i) for i in range(4)]), filename, 50)\n",
    "    datapairs = list(zip(data, meta))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    names = []\n",
    "    col_name_tpls = []\n",
    "    for sensor_data, stream_object in datapairs:\n",
    "        meta_dict = stream_object.metadata\n",
    "        # print(meta_dict)\n",
    "        name = meta_dict[\"NAME\"]\n",
    "        names.append(name)\n",
    "        n_cols = len(sensor_data)\n",
    "        col_names = []\n",
    "        for i in range(n_cols):\n",
    "            col_name = name + \"_\" + str(i)\n",
    "            col_names.append(col_name)\n",
    "            df[col_name] = pd.Series(sensor_data.T[:,i])\n",
    "        col_name_tpls.append(col_names)\n",
    "    df.index = pd.TimedeltaIndex(freq=\"20ms\", start=0.0, periods=len(df))\n",
    "    return df, col_name_tpls\n",
    "\n",
    "def trim_data(data_frame, start=0.0, end=None):\n",
    "    if end:\n",
    "        df = data_frame[pd.Timedelta(10**9 * start):pd.Timedelta(10**9 * end)]\n",
    "    else:\n",
    "        df = data_frame[pd.Timedelta(10**9 * start):]\n",
    "    return df\n",
    "\n",
    "def cut_data(data_frame, cuts):\n",
    "    df_cut_list = np.ndarray(shape=(len(cuts),) + cut_shape)\n",
    "    for i, cut in enumerate(cuts):\n",
    "        df_i = data_frame[pd.Timedelta(10**9 * cut[0]):pd.Timedelta(10**9 * cut[1])]\n",
    "        start_chanel = 0\n",
    "        if len(df_i) < 100:\n",
    "            continue\n",
    "        if not use_rotation_sensor:\n",
    "            start_chanel = 5\n",
    "        df_cut_list[i, : , :] = df_i.iloc[0: 100, start_chanel:8]\n",
    "\n",
    "    return df_cut_list\n",
    "\n",
    "\n",
    "def find_peaks(df, sensor, start=0.0, end=None, sel_method=\"right\"):\n",
    "    peaks = []\n",
    "    if end:\n",
    "        df = df[pd.Timedelta(10**9 * start):pd.Timedelta(10**9 * end)]\n",
    "    else:\n",
    "        df = df[pd.Timedelta(10**9 * start):]\n",
    "\n",
    "    for i in df.index:\n",
    "        value = df[sensor][i]\n",
    "        if sel_method == \"right\":\n",
    "            cond = value > 7.5\n",
    "        elif sel_method == \"left\":\n",
    "            cond = value < -1\n",
    "        if cond:\n",
    "            new = True\n",
    "            for peak in peaks:\n",
    "                if i - pd.Timedelta(10**9) < peak + pd.Timedelta(10**9):\n",
    "                    new = False\n",
    "                    break\n",
    "            if new:\n",
    "                peaks.append(i)\n",
    "    cuts = []\n",
    "    for peak in peaks:\n",
    "        t = peak.value / 10 ** 9\n",
    "        cuts.append((t-1, t+1))\n",
    "    return cuts \n",
    "\n",
    "def normalize_cuts(cuts):\n",
    "    for i in range(len(cuts)):\n",
    "        cuts[i, : , :] = cuts[i]/normalize_vector\n",
    "    return cuts\n",
    "  \n",
    "\n",
    "def plot_dataframe(df, col_name_tpls):\n",
    "    for col_name_tpl in col_name_tpls:\n",
    "        for col_name in col_name_tpl:\n",
    "            fig = df[col_name].plot()\n",
    "            fig.set_title(col_name)\n",
    "            plt.show()\n",
    "\n",
    "def plot_cuts(cuts, sensor=None):\n",
    "    if sensor is None:\n",
    "        for i, cut in enumerate(cuts):\n",
    "            plt.plot(cut, label=str(i))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return\n",
    "    for cut in cuts:\n",
    "        cut = cut[sensor]\n",
    "        cut = cut.values.reshape(-1,1)\n",
    "        print(cut.shape)\n",
    "        normed_matrix = normalize(cut, axis=0, norm='l1')\n",
    "        plt.plot(normed_matrix)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, lable=None):\n",
    "    data, meta = read(\" \".join([\"a:\" + str(i) for i in range(4)]), filename, 50)\n",
    "    datapairs = list(zip(data, meta))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    names = []\n",
    "    col_name_tpls = []\n",
    "    for sensor_data, stream_object in datapairs:\n",
    "        meta_dict = stream_object.metadata\n",
    "        # print(meta_dict)\n",
    "        name = meta_dict[\"NAME\"]\n",
    "        names.append(name)\n",
    "        n_cols = len(sensor_data)\n",
    "        col_names = []\n",
    "        for i in range(n_cols):\n",
    "            col_name = name + \"_\" + str(i)\n",
    "            col_names.append(col_name)\n",
    "            df[col_name] = pd.Series(sensor_data.T[:,i])\n",
    "        col_name_tpls.append(col_names)\n",
    "    df.index = pd.TimedeltaIndex(freq=\"20ms\", start=0.0, periods=len(df))\n",
    "    return df, col_name_tpls\n",
    "\n",
    "def trim_data(data_frame, start=0.0, end=None):\n",
    "    if end:\n",
    "        df = data_frame[pd.Timedelta(10**9 * start):pd.Timedelta(10**9 * end)]\n",
    "    else:\n",
    "        df = data_frame[pd.Timedelta(10**9 * start):]\n",
    "    return df\n",
    "\n",
    "def cut_data(data_frame, cuts):\n",
    "    df_cut_list = np.ndarray(shape=(len(cuts),) + cut_shape)\n",
    "    for i, cut in enumerate(cuts):\n",
    "        df_i = data_frame[pd.Timedelta(10**9 * cut[0]):pd.Timedelta(10**9 * cut[1])]\n",
    "        prev_sensor_channels = 0\n",
    "        if len(df_i) < 100:\n",
    "            continue\n",
    "        if use_rotation_sensor:\n",
    "            df_cut_list[i, : , 0:5] = df_i.iloc[0: 100, 0:5]\n",
    "            prev_sensor_channels += 5\n",
    "        if use_accelerometer_sensor:\n",
    "            df_cut_list[i, : , prev_sensor_channels:prev_sensor_channels+3] = df_i.iloc[0: 100, 5:8]\n",
    "            prev_sensor_channels += 3\n",
    "        if use_gyroscope_sensor:\n",
    "            df_cut_list[i, : , prev_sensor_channels:prev_sensor_channels+3] = df_i.iloc[0: 100, 8:11]\n",
    "            prev_sensor_channels += 3\n",
    "        if use_magnetic_sensor:\n",
    "            df_cut_list[i, : , prev_sensor_channels:prev_sensor_channels+3] = df_i.iloc[0: 100, 11:14]\n",
    "            prev_sensor_channels += 3\n",
    "    return df_cut_list\n",
    "\n",
    "\n",
    "def find_peaks(df, sensor, start=0.0, end=None):\n",
    "    peaks = []\n",
    "    if end:\n",
    "        df = df[pd.Timedelta(10**9 * start):pd.Timedelta(10**9 * end)]\n",
    "    else:\n",
    "        df = df[pd.Timedelta(10**9 * start):]\n",
    "\n",
    "    for i in df.index:\n",
    "        value = df[sensor][i]\n",
    "        if abs(value) > 7:\n",
    "            new = True\n",
    "            for peak in peaks:\n",
    "                if i - pd.Timedelta(10**9) < peak + pd.Timedelta(10**9):\n",
    "                    new = False\n",
    "                    break\n",
    "            if new:\n",
    "                peaks.append(i)\n",
    "    cuts = []\n",
    "    for peak in peaks:\n",
    "        t = peak.value / 10 ** 9\n",
    "        cuts.append((t-1, t+1))\n",
    "    return cuts \n",
    "\n",
    "def normalize_cuts(cuts):\n",
    "    for i in range(len(cuts)):\n",
    "        cuts[i, : , :] = cuts[i]/normalize_vector\n",
    "    return cuts\n",
    "  \n",
    "\n",
    "def plot_dataframe(df, col_name_tpls):\n",
    "    for col_name_tpl in col_name_tpls:\n",
    "        for col_name in col_name_tpl:\n",
    "            fig = df[col_name].plot()\n",
    "            fig.set_title(col_name)\n",
    "            plt.show()\n",
    "\n",
    "def plot_cuts(cuts, sensor=None):\n",
    "    if sensor is None:\n",
    "        for i, cut in enumerate(cuts):\n",
    "            plt.plot(cut, label=str(i))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        return\n",
    "    for cut in cuts:\n",
    "        cut = cut[sensor]\n",
    "        cut = cut.values.reshape(-1,1)\n",
    "        print(cut.shape)\n",
    "        normed_matrix = normalize(cut, axis=0, norm='l1')\n",
    "        plt.plot(normed_matrix)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/swipe_left_20_0.mkv', 'data/swipe_left_20_1.mkv', 'data/swipe_left_20_2.mkv', 'data/swipe_left_20_3.mkv', 'data/swipe_left_20_4.mkv']\n",
      "['data/swipe_right_20_0.mkv', 'data/swipe_right_20_1.mkv', 'data/swipe_right_20_2.mkv', 'data/swipe_right_20_3.mkv', 'data/swipe_right_20_4.mkv']\n",
      "['data/noise_0.mkv', 'data/noise_1.mkv']\n"
     ]
    }
   ],
   "source": [
    "for gesture in patterns.keys():\n",
    "    gesture_file_list = glob(data_folder + patterns[gesture])\n",
    "    print(gesture_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def export_data(force_overwrite=False, do_result_plots=False):\n",
    "    \"\"\"export all the data!!\n",
    "    force_overwrite: overwrite already exported data\n",
    "    do_result_plots: show plots of resulting gesture cuts again.\n",
    "    \"\"\"\n",
    "    for gesture in patterns.keys():\n",
    "        gesture_file_list = glob(data_folder + patterns[gesture])\n",
    "        k = 0\n",
    "        for filename in gesture_file_list:\n",
    "            assert filename.count(\"/\") == 1\n",
    "            rev_file = filename[::-1]\n",
    "\n",
    "            ind = len(filename) - rev_file.index(\"_\")\n",
    "            gesture_name = filename[filename.index(\"/\")+1:ind-1]\n",
    "            gesutre_name_copy = gesture_name\n",
    "            while gesture_name[-1].lower() not in string.ascii_lowercase:\n",
    "                gesture_name = gesture_name[:-1]\n",
    "            try:\n",
    "                num_cuts = int(gesutre_name_copy[len(gesture_name) - len(gesutre_name_copy) +1:])\n",
    "            except:\n",
    "                print(f\"WARNING, in FILE DOES NOT SET AMOUNT OF CUTS: {filename}\")\n",
    "                num_cuts = False\n",
    "            number = filename[ind:filename.index(\".\")]\n",
    "            if os.path.isfile(data_split_folder + gesture_name + \"_\" + number + \"_000.csv\") and not force_overwrite:\n",
    "                print(f\"File {filename} was already exported, force overwrite if needed.\")\n",
    "                continue\n",
    "            df, col_name_tpls = read_file(filename)\n",
    "            df[\"Cywee Accelerometer Sensor_2\"].plot()\n",
    "            plt.show()\n",
    "            start = int(input(\"start?\"))\n",
    "            try:\n",
    "                end = int(input(\"end?\"))\n",
    "            except:\n",
    "                end = False\n",
    "            if end:\n",
    "                trimed_df = trim_data(df, start, end)\n",
    "            else:\n",
    "                trimed_df = trim_data(df, start)\n",
    "            peaks = find_peaks(trimed_df, \"Cywee Accelerometer Sensor_2\")\n",
    "            print(len(peaks), \":\", peaks)\n",
    "            cuts = normalize_cuts(cut_data(trimed_df, peaks))\n",
    "            print(\"Found cuts:\", len(cuts))\n",
    "            plot_cuts(cuts)\n",
    "            r = eval(input(\"remove cuts?? (divide by \\',\\') \"))\n",
    "            assert type(r) == list\n",
    "            l_cuts = []   # list to keep cuts\n",
    "            for i, cut in enumerate(cuts):\n",
    "                if i not in r:\n",
    "                    l_cuts.append(cut)\n",
    "            #cuts = np.asarray(l)\n",
    "            if num_cuts:\n",
    "                if len(l_cuts) != num_cuts:\n",
    "                    print(f\"WARNING: expected {num_cuts} but got {len(l_cuts)}\")\n",
    "                else:\n",
    "                    print(\"correct number of cuts reached\")\n",
    "            for n, cut in enumerate(l_cuts):\n",
    "                n_str = str(n)\n",
    "                while len(n_str) < 3:\n",
    "                    n_str = \"0\" + n_str\n",
    "                np.savetxt(data_split_folder + gesture_name + \"_\" + number + \"_\" + n_str + \".csv\", cut, delimiter=\",\")\n",
    "            if do_result_plots:\n",
    "                plot_cuts(l_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(patterns=patterns):\n",
    "    data_dict = {pattern : [] for pattern in patterns}\n",
    "    for gesture in patterns:\n",
    "        gesture_file_list = glob(data_split_folder + \"/*\" + gesture +\"*\")\n",
    "        for i, gesture_file in enumerate(gesture_file_list):\n",
    "            data = np.loadtxt(gesture_file, delimiter=\",\")\n",
    "            data_dict[gesture].append(data)\n",
    "    \n",
    "    #combine into X and y\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for gesture in patterns:\n",
    "        X.extend(data_dict[gesture])\n",
    "        y.extend([gestures_reverse[gesture]] * len(data_dict[gesture]))\n",
    "    \n",
    "    \n",
    "    return np.asarray(X), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# computer-aided selection of trial windows\n",
    "\n",
    "### still have to select the correct ones.\n",
    "#### enter trials to remove as python list with their indices, e.g. [1, 21, 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/swipe_left_20_0.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_left_20_1.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_left_20_2.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_left_20_3.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_left_20_4.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_right_20_0.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_right_20_1.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_right_20_2.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_right_20_3.mkv was already exported, force overwrite if needed.\n",
      "File data/swipe_right_20_4.mkv was already exported, force overwrite if needed.\n",
      "WARNING, in FILE DOES NOT SET AMOUNT OF CUTS: data/noise_0.mkv\n",
      "File data/noise_0.mkv was already exported, force overwrite if needed.\n",
      "WARNING, in FILE DOES NOT SET AMOUNT OF CUTS: data/noise_1.mkv\n",
      "File data/noise_1.mkv was already exported, force overwrite if needed.\n"
     ]
    }
   ],
   "source": [
    "export_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data and train keras model, export model as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  learn_clasifyer(data, lables):\n",
    "    print(data.shape)\n",
    "    model = keras.Sequential([\n",
    "        #keras.layers.Flatten(),\n",
    "        keras.layers.Flatten(input_shape=cut_shape),\n",
    "        keras.layers.Dense(100 * len(normalize_vector), activation=tf.nn.relu),\n",
    "        keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(data, lables, epochs=50)\n",
    "    test_loss, test_acc = model.evaluate(data, lables)\n",
    "\n",
    "    print('Test accuracy:', test_acc)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 100, 6)\n",
      "WARNING:tensorflow:From /home/gende/repos/PyAV/venvs/Linux.4.4.0-17134-Microsoft.cpython3.6/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/50\n",
      "193/193 [==============================] - 0s 1ms/sample - loss: 0.4998 - acc: 0.8187\n",
      "Epoch 2/50\n",
      "193/193 [==============================] - 0s 298us/sample - loss: 0.0589 - acc: 0.9845\n",
      "Epoch 3/50\n",
      "193/193 [==============================] - 0s 335us/sample - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 4/50\n",
      "193/193 [==============================] - 0s 308us/sample - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 5/50\n",
      "193/193 [==============================] - 0s 320us/sample - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 6/50\n",
      "193/193 [==============================] - 0s 248us/sample - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "193/193 [==============================] - 0s 413us/sample - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "193/193 [==============================] - 0s 290us/sample - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "193/193 [==============================] - 0s 352us/sample - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "193/193 [==============================] - 0s 304us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "193/193 [==============================] - 0s 311us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "193/193 [==============================] - 0s 366us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "193/193 [==============================] - 0s 286us/sample - loss: 9.7911e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "193/193 [==============================] - 0s 402us/sample - loss: 9.1292e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "193/193 [==============================] - 0s 352us/sample - loss: 8.5035e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "193/193 [==============================] - 0s 271us/sample - loss: 7.8693e-04 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "193/193 [==============================] - 0s 292us/sample - loss: 7.3850e-04 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "193/193 [==============================] - 0s 346us/sample - loss: 6.9362e-04 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "193/193 [==============================] - 0s 309us/sample - loss: 6.5549e-04 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "193/193 [==============================] - 0s 328us/sample - loss: 6.1691e-04 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "193/193 [==============================] - 0s 318us/sample - loss: 5.8002e-04 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "193/193 [==============================] - 0s 318us/sample - loss: 5.4196e-04 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "193/193 [==============================] - 0s 260us/sample - loss: 5.1322e-04 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "193/193 [==============================] - 0s 311us/sample - loss: 4.8918e-04 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "193/193 [==============================] - 0s 243us/sample - loss: 4.6708e-04 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "193/193 [==============================] - 0s 345us/sample - loss: 4.4238e-04 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "193/193 [==============================] - 0s 297us/sample - loss: 4.2309e-04 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "193/193 [==============================] - 0s 267us/sample - loss: 4.0456e-04 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "193/193 [==============================] - 0s 318us/sample - loss: 3.7989e-04 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "193/193 [==============================] - 0s 327us/sample - loss: 3.8436e-04 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "193/193 [==============================] - 0s 274us/sample - loss: 3.6585e-04 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "193/193 [==============================] - 0s 237us/sample - loss: 3.4205e-04 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "193/193 [==============================] - 0s 257us/sample - loss: 3.2186e-04 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "193/193 [==============================] - 0s 241us/sample - loss: 3.0683e-04 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "193/193 [==============================] - 0s 418us/sample - loss: 2.9123e-04 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "193/193 [==============================] - 0s 318us/sample - loss: 2.8015e-04 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "193/193 [==============================] - 0s 294us/sample - loss: 2.6664e-04 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "193/193 [==============================] - 0s 370us/sample - loss: 2.5495e-04 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "193/193 [==============================] - 0s 344us/sample - loss: 2.4345e-04 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "193/193 [==============================] - 0s 329us/sample - loss: 2.3256e-04 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "193/193 [==============================] - 0s 338us/sample - loss: 2.2069e-04 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "193/193 [==============================] - 0s 294us/sample - loss: 2.1211e-04 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "193/193 [==============================] - 0s 283us/sample - loss: 2.0540e-04 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "193/193 [==============================] - 0s 292us/sample - loss: 1.9885e-04 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "193/193 [==============================] - 0s 340us/sample - loss: 1.9285e-04 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "193/193 [==============================] - 0s 316us/sample - loss: 1.8633e-04 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "193/193 [==============================] - 0s 289us/sample - loss: 1.8046e-04 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "193/193 [==============================] - 0s 318us/sample - loss: 1.7520e-04 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "193/193 [==============================] - 0s 302us/sample - loss: 1.7037e-04 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "193/193 [==============================] - 0s 311us/sample - loss: 1.6430e-04 - acc: 1.0000\n",
      "193/193 [==============================] - 0s 308us/sample - loss: 1.6048e-04 - acc: 1.0000\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf_model = learn_clasifyer(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 149us/sample - loss: 0.1464 - acc: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.146413645377386, 0.95384616]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gende/repos/PyAV/venvs/Linux.4.4.0-17134-Microsoft.cpython3.6/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/gende/repos/PyAV/venvs/Linux.4.4.0-17134-Microsoft.cpython3.6/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1450684"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.save('keras_gesture_model.h5')\n",
    "\n",
    "converter = lite.TFLiteConverter.from_keras_model_file('keras_gesture_model.h5')\n",
    "tfmodel = converter.convert()\n",
    "open (\"keras_gesture_model.tflite\" , \"wb\") .write(tfmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After running the notebook:\n",
    " - copy the 'keras_gesture_model.tflite' into the res folder of 'CookbookMotion'\n",
    " - Recompile and test on the watch!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
